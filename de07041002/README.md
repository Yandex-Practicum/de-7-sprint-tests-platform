# Комментарий от тестописателя
На платформе невозможно реализовать Hadoop-кластер и HDFS — чтобы дать студенту возможность писать и проверять код на платформе, мы подготовили файловую структуру похожую на ту, что доступна на кластере.

Важные отличия:

1. Папки для чтения лежат в каталоге `/home/student` — если на кластере студент читает данные из `/user/master/data/events/date=2022-05-25`, то на платформе это будет `/home/student/user/master/data/events/date=2022-05-25`.

2. Папки для записи лежат в каталоге `/home/student/tmp` — если на кластере студент пишет данные в `/user/USERNAME/analytics/test`, то на платформе это будет `/home/student/tmp/user/USERNAME/analytics/test`.

3. На платформу не получится завести все данные с кластера. Взяли данные за `2022-05-01`, `2022-05-25` и `2022-05-31` в формате JSON из `master` и папки `channels`, `tags_verified` из `snapshots`. Создали каталог `USERNAME` с данными за май 2022-ого партиционированные по `date` и `event_type` в формате Parquet.

4. Имя пользователя на платформе `USERNAME`, а на кластере нужно будет использовать свой логин (выдаёт Telegram-бот).

### ВАЖНО:

Spark по умолчанию не может перезаписывать данные — возникает конфликт с тем как устроена работа прекода в сниппетах.

1) Прекод только в тесте — не работает **Выполнить**, но работает **Проверить**. 

2) Прекод только в JSON-конфиге — работает и **Выполнить**, и **Проверить**, но только если используется `.mode("overwrite")` для операции записи в Spark.

**Note:** Без `.mode("overwrite")`  во время Проверки будет ошибка, что файл уже существует (хотя он создаётся в задаче). Воспроизводится только в сниппетах. Выглядит так,  будто решение студента и, возможно, авторское выполняются дважды, до и во время тестов.

### ТАКЖЕ ВАЖНО
Критически важно, чтобы студент формировал именно такие пути и именно с такими аргументами, так как аргументы командной строки будут жёстко заданы в тесте или прекоде:

`f"{base_input_path}/date={date}"`

`f"{base_output_path}/date={date}"`

На кластере студент может сам решить с какими аргументами запускать свои джобы и соответственно писать скрипты под них, НО не в тренажёре. Важно, чтобы он работал с  аргументами `date`, `base_input_path` и `base_output_path` в том виде, в котором мы определяем их в тесте или прекоде — значит это должно быть отражено в условии.

Например, в условии задачи можно дать пример того, какие аргументы будут передаваться во время запуска скрипта:

`date` — `"2022-05-31"`
`base_input_path` — `"/home/student/user/master/data/events"`
`base_output_path` — `"/home/student/tmp/user/USERNAME/data/events"`